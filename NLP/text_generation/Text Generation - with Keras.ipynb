{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Text Generation with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facebooks Fast Text library for finding semantic similarity and to perform text classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text generation is one of the state-of-the-art applications of NLP. Deep learning techniques are being used for a variety of text generation tasks such as writing poetry, generating scripts for movies, and even for composing music. However, in this article we will see a very simple example of text generation where given an input string of words, we will predict the next word. We will use the raw text from Shakespeare's famous novel \"Macbeth\" and will use that to predict the next word given a sequence of input words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from random import randint\n",
    "import re\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\imanursar\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "nltk.data.path.append(\"E:\\programs\\nltk_data\")\n",
    "nltk.data.path.append(\"E:\\programs\\nltk_data\\corpora\")\n",
    "nltk.data.path.append(\"E:\\programs\\nltk_data\\tokenizers\")\n",
    "from nltk.corpus import gutenberg as gut\n",
    "print(gut.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The Tragedie of Macbeth by William Shakespeare 1603]\n",
      "\n",
      "\n",
      "Actus Primus. Scoena Prima.\n",
      "\n",
      "Thunder and Lightning. Enter three Witches.\n",
      "\n",
      "  1. When shall we three meet againe?\n",
      "In Thunder, Lightning, or in Raine?\n",
      "  2. When the Hurley-burley's done,\n",
      "When the Battaile's lost, and wonne\n",
      "\n",
      "   3. That will be ere the set of Sunne\n",
      "\n",
      "   1. Where the place?\n",
      "  2. Vpon the Heath\n",
      "\n",
      "   3. There to meet with Macbeth\n",
      "\n",
      "   1. I come, Gray-Malkin\n",
      "\n",
      "   All. Padock calls anon: faire is foule, and foule is faire,\n",
      "Houer through \n"
     ]
    }
   ],
   "source": [
    "macbeth_text = nltk.corpus.gutenberg.raw('shakespeare-macbeth.txt')\n",
    "print(macbeth_text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(sentence):\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    \n",
    "    #added\n",
    "    #removes spaces from at the end \n",
    "    sentence = re.sub(r\"\\s+$\", \"\", sentence)\n",
    "    # Converting to Lowercase\n",
    "    sentence = sentence.lower()\n",
    "    # Lemmatization\n",
    "    # reduce the word into dictionary root form\n",
    "#     sentence = sentence.split()\n",
    "#     sentence = [stemmer.lemmatize(word) for word in sentence]\n",
    "#     sentence = ' '.join(sentence)\n",
    "    \n",
    "    #remove stopwords\n",
    "    sentence = remove_stopwords(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The Tragedie of Macbeth by William Shakespeare 1603]\n",
      "\n",
      "\n",
      "Actus Primus. Scoena Prima.\n",
      "\n",
      "Thunder and Lightning. Enter three Witches.\n",
      "\n",
      "  1. When shall we three meet againe?\n",
      "In Thunder, Lightning, or in Raine?\n",
      "  2. When the Hurley-burley's done,\n",
      "When the Battaile's lost, and wonne\n",
      "\n",
      "   3. That will be ere the set of Sunne\n",
      "\n",
      "   1. Where the place?\n",
      "  2. Vpon the Heath\n",
      "\n",
      "   3. There to meet with Macbeth\n",
      "\n",
      "   1. I come, Gray-Malkin\n",
      "\n",
      "   All. Padock calls anon: faire is foule, and foule is faire,\n",
      "Houer through the fogge and filthie ayre.\n",
      "\n",
      "Exeunt.\n",
      "\n",
      "\n",
      "Scena Secunda.\n",
      "\n",
      "Alarum within. Enter King Malcome, Donalbaine, Lenox, with\n",
      "attendants,\n",
      "meeting a bleeding Captaine.\n",
      "\n",
      "  King. What bloody man is that? he can report,\n",
      "As seemeth by his plight, of the Reuolt\n",
      "The newest state\n",
      "\n",
      "   Mal. This is the Serieant,\n",
      "Who like a good and hardie Souldier fought\n",
      "'Gainst my Captiuitie: Haile braue friend;\n",
      "Say to the King, the knowledge of the Broyle,\n",
      "As thou didst leaue it\n",
      "\n",
      "   Cap. Doubtfull it stood,\n",
      "As two spent Swimmers, t\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tragedie macbeth william shakespeare actus primus scoena prima thunder lightning enter witches shall meet againe thunder lightning raine hurley burley battaile lost wonne ere set sunne place vpon heath meet macbeth come gray malkin padock calls anon faire foule foule faire houer fogge filthie ayre exeunt scena secunda alarum enter king malcome donalbaine lenox attendants meeting bleeding captaine king bloody man report seemeth plight reuolt newest state mal serieant like good hardie souldier fou'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(macbeth_text[:1000])\n",
    "print(\"\\n\")\n",
    "macbeth_text = preprocess_text(macbeth_text)\n",
    "macbeth_text[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Words to Numbers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenize (convert words to vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words: 9062\n",
      "Unique Words: 3231\n"
     ]
    }
   ],
   "source": [
    "macbeth_text_words = (word_tokenize(macbeth_text))\n",
    "n_words = len(macbeth_text_words)\n",
    "unique_words = len(set(macbeth_text_words))\n",
    "print('Total Words: %d' % n_words)\n",
    "print('Unique Words: %d' % unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert tokenized words to numbers, the Tokenizer class from the keras.preprocessing.text. A dictionary will be created where the keys will represent words, whereas integers will represent the corresponding values of the dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=3437)\n",
    "tokenizer.fit_on_texts(macbeth_text_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the dictionary that contains words and their corresponding indexes, the word_index attribute of the tokenizer object can be used: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "word_2_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(macbeth_text_words[500])\n",
    "print(word_2_index[macbeth_text_words[500]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying the Shape of the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text generation falls in the category of many-to-one sequence problems since the input is a sequence of words and output is a single word. (LSTM), which is a type of recurrent neural network to create our text generation model. LSTM accepts data in a 3-dimensional format ( number of samples, number of time-steps, features per time step). Since the output will be a single word, the shape of the output will be 2-dimensional ( number of samples, number of unique words in the corpus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = []\n",
    "output_words = []\n",
    "input_seq_length = 100\n",
    "\n",
    "for i in range(0, n_words - input_seq_length , 1):\n",
    "    in_seq = macbeth_text_words[i:i + input_seq_length]\n",
    "    out_seq = macbeth_text_words[i + input_seq_length]\n",
    "    input_sequence.append([word_2_index[word] for word in in_seq])\n",
    "    output_words.append(word_2_index[out_seq])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input_seq_length is set to 100, which means that our input sequence will consist of 100 words. \n",
    "\n",
    "Next, we execute a loop where in the first iteration, integer values for the\n",
    "first 100 words from the text are appended to the input_sequence list. The 101st word is appended to the output_words list. During the second iteration, a sequence of words that starts from the 2nd word in the text and ends at the 101st word is stored in the input_sequence list, and the 102nd word is stored in the output_words array, and so on. \n",
    "\n",
    "A total of 17150 input sequences will be generated since there are 17250 total\n",
    "words in the dataset (100 less than the total words). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[698, 6, 1179, 1180, 273, 1181, 1182, 274, 151, 699, 4, 172, 5, 200, 51, 151, 699, 1183, 1184, 1185, 1186, 226, 700, 78, 173, 494, 115, 7, 701, 200, 6, 14, 1187, 1188, 1189, 702, 201, 227, 275, 275, 227, 1190, 1191, 703, 79, 35, 50, 276, 228, 4, 13, 1192, 202, 38, 229, 277, 704, 1193, 13, 80, 31, 152, 1194, 1195, 705, 495, 203, 41, 1196, 20, 16, 1197, 357, 706, 358, 1198, 87, 707, 278, 13, 496, 1199, 3, 497, 88, 498, 708, 359, 709, 1200, 24, 710, 1201, 59, 1202, 1203, 1204, 711, 1205, 1206]\n"
     ]
    }
   ],
   "source": [
    "print(input_sequence[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's normalize our input sequences by dividing the integers in the sequences by the largest integer value. The following script also converts the output into 2-dimensional format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(input_sequence, (len(input_sequence), input_seq_length, 1))\n",
    "X = X / float(vocab_size)\n",
    "y = to_categorical(output_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (8962, 100, 1)\n",
      "y shape: (8962, 3232)\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 800)          2566400   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 800)          5123200   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 800)               5123200   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3232)              2588832   \n",
      "=================================================================\n",
      "Total params: 15,401,632\n",
      "Trainable params: 15,401,632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(800, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(800, return_sequences=True))\n",
    "model.add(LSTM(800))\n",
    "\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8962 samples\n",
      "Epoch 1/10\n",
      "8962/8962 [==============================] - 52s 6ms/sample - loss: 7.3045\n",
      "Epoch 2/10\n",
      "8962/8962 [==============================] - 52s 6ms/sample - loss: 7.3039\n",
      "Epoch 3/10\n",
      "8962/8962 [==============================] - 52s 6ms/sample - loss: 7.3042\n",
      "Epoch 4/10\n",
      "8962/8962 [==============================] - 52s 6ms/sample - loss: 7.3077\n",
      "Epoch 5/10\n",
      "8962/8962 [==============================] - 52s 6ms/sample - loss: 7.3103\n",
      "Epoch 6/10\n",
      "8962/8962 [==============================] - 52s 6ms/sample - loss: 7.3018\n",
      "Epoch 7/10\n",
      "8962/8962 [==============================] - 52s 6ms/sample - loss: 7.3037\n",
      "Epoch 8/10\n",
      "8962/8962 [==============================] - 52s 6ms/sample - loss: 7.2987\n",
      "Epoch 9/10\n",
      "8962/8962 [==============================] - 52s 6ms/sample - loss: 7.2967\n",
      "Epoch 10/10\n",
      "8962/8962 [==============================] - 52s 6ms/sample - loss: 7.2961\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, \n",
    "          batch_size=64, \n",
    "          epochs=10, \n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make predictions, we will randomly select a sequence from the convert it into a 3-dimentional shape and then pass it to the predict() method of the \n",
    "trained model.\n",
    "\n",
    "The model will return a one-hot encoded array where the index that contains 1 will be the index value of the next word. The index value is then passed to the index_2_word dictionary, where the word index is used as a key. The index_2_word dictionary will return the word that belong to the index that is passed as a key to the dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## index to word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad thee thane cawdor addition haile worthy thane thine banq deuill speake true macb thane cawdor liues doe dresse borrowed robes ang thane liues vnder heauie iudgement beares life deserues loose combin norway lyne rebell hidden helpe vantage labour countreyes wracke know treasons capitall confess prou haue ouerthrowne macb glamys thane cawdor greatest behinde thankes paines doe hope children shall kings gaue thane cawdor promis lesse banq trusted home enkindle vnto crowne thane cawdor tis strange oftentimes winne vs harme instruments darknesse tell vs truths winne vs honest trifles betray deepest consequence cousins word pray macb truths told happy prologues\n"
     ]
    }
   ],
   "source": [
    "random_seq_index = np.random.randint(0, len(input_sequence)-1)\n",
    "random_seq = input_sequence[random_seq_index]\n",
    "index_2_word = dict(map(reversed, word_2_index.items()))\n",
    "word_sequence = [index_2_word[value] for value in random_seq]\n",
    "print(' '.join(word_sequence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we will print the next 100 words that follow the above sequence of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    int_sample = np.reshape(random_seq, (1, len(random_seq), 1))\n",
    "    int_sample = int_sample / float(vocab_size)\n",
    "    \n",
    "    predicted_word_index = model.predict(int_sample, verbose=0)\n",
    "    predicted_word_id = np.argmax(predicted_word_index)\n",
    "\n",
    "    word_sequence.append(index_2_word[predicted_word_id])\n",
    "    \n",
    "    random_seq.append(predicted_word_id)\n",
    "    random_seq = random_seq[1:len(random_seq)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word_sequence variable now contains our input sequence of words, along with the next 100 predicted words. The word_sequence variable contains sequence of words in the form of list. We can simply join the words in the list to get the final output sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bad thee thane cawdor addition haile worthy thane thine banq deuill speake true macb thane cawdor liues doe dresse borrowed robes ang thane liues vnder heauie iudgement beares life deserues loose combin norway lyne rebell hidden helpe vantage labour countreyes wracke know treasons capitall confess prou haue ouerthrowne macb glamys thane cawdor greatest behinde thankes paines doe hope children shall kings gaue thane cawdor promis lesse banq trusted home enkindle vnto crowne thane cawdor tis strange oftentimes winne vs harme instruments darknesse tell vs truths winne vs honest trifles betray deepest consequence cousins word pray macb truths told happy prologues macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb macb\n"
     ]
    }
   ],
   "source": [
    "final_output = \"\"\n",
    "for word in word_sequence:\n",
    "    final_output = final_output + \" \" + word\n",
    "print(final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the results, I have the following recommendations for you:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Change the hyper parameters, including the size and number of LSTM layers and number of epochs to see if you get better results.\n",
    "\n",
    "2. Try to remove the stop words like is, am, are from training set to generate \n",
    "words other than stop words in the test set (although this will depend on the type of application).\n",
    "\n",
    "3. Create a character-level text generation model that predicts the next N characters. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
