{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "# NLP library\n",
    "import nltk\n",
    "import re\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# function\n",
    "import sys\n",
    "sys.path.append('function/')\n",
    "from ursar import nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function\n",
    "def preprocess_text(sentence):\n",
    "    id_stop = set(nltk.corpus.stopwords.words('indonesian'))\n",
    "    factory_Stemmer = StemmerFactory()\n",
    "    stemmer = factory_Stemmer.create_stemmer()\n",
    "    sentence = re.sub(r'\\W', ' ', str(sentence))\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "    sentence = re.sub(r'\\^[a-zA-Z]\\s+', ' ', sentence)\n",
    "    sentence = sentence.replace(\"\\n\",\" \")\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    sentence = re.sub(r\"\\s+$\", \"\", sentence)\n",
    "    sentence = re.sub(r\"^\\s+\", \"\", sentence)\n",
    "    sentence = sentence.lower()\n",
    "    sentence = sentence.split()\n",
    "    sentence = [word for word in sentence if word not in id_stop]\n",
    "    sentence = [word for word in sentence if len(word) > 3]\n",
    "    sentence = ' '.join(sentence)\n",
    "    sentence = stemmer.stem(sentence)\n",
    "    return sentence\n",
    "\n",
    "def tokenize_matrix(corpus,mode):\n",
    "    #corpus, 5000, 'post', 120\n",
    "    # create the tokenizer\n",
    "    # load label train dataset file here\n",
    "    with open('model/tokenizer_ann', 'rb') as picklefile:\n",
    "        tokenizer = pickle.load(picklefile)\n",
    "\n",
    "    # encode training data set\n",
    "    sen = tokenizer.texts_to_matrix(corpus, mode=mode)\n",
    "    return(sen)\n",
    "\n",
    "def tokenize_embedding(corpus,padding_type,max_length):\n",
    "    #corpus, 5000, 'post', 120\n",
    "    # create the tokenizer\n",
    "    # load label train dataset file here\n",
    "    with open('model/tokenizer_embed', 'rb') as picklefile:\n",
    "        tokenizer = pickle.load(picklefile)\n",
    "\n",
    "    # encode training data set\n",
    "    sen = tokenizer.texts_to_sequences(corpus)\n",
    "    sen = pad_sequences(sen, padding=padding_type, maxlen=max_length)\n",
    "    return(sen)\n",
    "\n",
    "def predict_embedding(reviews, model,input):\n",
    "    # apply preprocess_text function to out training dataset\n",
    "    # encode\n",
    "    if (input == \"embedding\"):\n",
    "        encoded = tokenize_embedding(reviews,'post', 120)\n",
    "    if (input == \"matrixs\"):\n",
    "        encoded = tokenize_matrix(reviews,\"freq\")\n",
    "    # prediction\n",
    "    yhat = model.predict(encoded, verbose=0)\n",
    "\n",
    "    if (yhat[0,0]>=0.5):\n",
    "        res = \"positive review\"\n",
    "    else:\n",
    "        res = \"negative review\"\n",
    "    return (res,yhat[0,0])\n",
    "\n",
    "def print_score (y_test,y_pred,y_probs):\n",
    "    print(\"comfusion matrix = \")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    (tn,fp,fn,tp) = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "    print(\"\")\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print('accuracy_score = ', accuracy)\n",
    "    bas = balanced_accuracy_score(y_test, y_pred)\n",
    "    print('balanced_accuracy_score = ', bas)\n",
    "    #balanced accuracy is equal to the arithmetic mean of sensitivity (true positive rate) and specificity (true negative rate),\n",
    "    #or the area under the ROC curve with binary predictions rather than scores.\n",
    "\n",
    "    #In multilabel classification,\n",
    "    #this function computes subset accuracy: the set of labels predicted for\n",
    "    #a sample must exactly match the corresponding set of labels in y_true\n",
    "\n",
    "    print(\"\")\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    aps = average_precision_score(y_test, y_pred)\n",
    "    print (\"precision score = \", precision)\n",
    "    print (\"average precision score = \", aps)\n",
    "    print (\"recall score = \", recall)\n",
    "\n",
    "    #precision An interesting one to look at is the accuracy of the positive pre‚Äê dictions; this is called the precision of the classifier\n",
    "    # recall, also called sensitivity or true positive rate (TPR): this is the ratio of positive instances that are correctly detected by the classifier\n",
    "    #precision = TP/TP + FP\n",
    "    #recall = TP/TP + FN\n",
    "\n",
    "    print(\"\")\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print (\"F1 score = \", f1)\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "    aucs = auc(recall, precision)\n",
    "    print (\"AUC of Precision-Recall Curve on Testing = \", aucs)\n",
    "    aucroc = roc_auc_score(y_test,y_probs)\n",
    "    print (\"AUC of ROC = \", aucroc)\n",
    "    gini = aucs*2 - 1\n",
    "    print(\"Gini = \", gini)\n",
    "\n",
    "    print(\"\")\n",
    "    cr = classification_report(y_test,y_pred)\n",
    "    print(\"classification_report\")\n",
    "    print(cr)\n",
    "\n",
    "    #The F1 score is the harmonic mean of precision and recall (Equation 3-3).\n",
    "    #Whereas the regular mean treats all values equally,\n",
    "    #the harmonic mean gives much more weight to low values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Test dataset\n",
      "\n",
      "data testing shape\n",
      "(185, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Load Test dataset\")\n",
    "test = pd.read_csv('DATA/test_data_restaurant.tsv', sep='\\t',header=None).sample(frac=1).reset_index(drop=True)\n",
    "test.columns = ['sentence', 'label']\n",
    "print(\"\\ndata testing shape\")\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "is the test dataset contain the null values?\n",
      "sentence    0\n",
      "label       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nis the test dataset contain the null values?\")\n",
    "print(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "change label for test dataset\n"
     ]
    }
   ],
   "source": [
    "test[\"label\"] = list(map(lambda x: 1 if x==\"positive\" else 0, test[\"label\"]))\n",
    "print(\"\\nchange label for test dataset\")\n",
    "test[\"label\"].unique()\n",
    "y_test = test[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "apply preprocess_text function to out testing dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"\\napply preprocess_text function to out testing dataset\")\n",
    "reviews_test = []\n",
    "sentences = list(test[\"sentence\"])\n",
    "for sen in sentences:\n",
    "    reviews_test.append(preprocess_text(sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "make token for test dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nmake token for test dataset\")\n",
    "token_test_ann = tokenize_matrix(reviews_test,\"freq\")\n",
    "token_test = tokenize_embedding(reviews_test,'post', 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "load matrix_ANN model\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nload matrix_ANN model\")\n",
    "model = load_model('model/model_matrix_ANN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Accuracy:  0.7892\n",
      "Testing loss:  0.4885\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(token_test_ann,y_test , verbose=False)\n",
    "print(\"\\nTesting Accuracy:  {:.4f}\".format(accuracy))\n",
    "print(\"Testing loss:  {:.4f}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "load CNN model\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nload CNN model\")\n",
    "model = load_model('model/model_CNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Accuracy:  0.8270\n",
      "Testing loss:  0.5228\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(token_test,y_test, verbose=False)\n",
    "print(\"\\nTesting Accuracy:  {:.4f}\".format(accuracy))\n",
    "print(\"Testing loss:  {:.4f}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "load CNN LSTM model\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nload CNN LSTM model\")\n",
    "model = load_model('model/model_CNN_LSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Accuracy:  0.7946\n",
      "Testing loss:  0.5262\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(token_test,y_test, verbose=False)\n",
    "print(\"\\nTesting Accuracy:  {:.4f}\".format(accuracy))\n",
    "print(\"Testing loss:  {:.4f}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "load CNN wiki model\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nload CNN wiki model\")\n",
    "model = load_model('model/model_CNN_wiki.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Accuracy:  0.7730\n",
      "Testing loss:  0.5976\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(token_test,y_test, verbose=False)\n",
    "print(\"\\nTesting Accuracy:  {:.4f}\".format(accuracy))\n",
    "print(\"Testing loss:  {:.4f}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "load CNN LSTM wiki model\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nload CNN LSTM wiki model\")\n",
    "model = load_model('model/model_CNN_LSTM_wiki.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Accuracy:  0.7676\n",
      "Testing loss:  0.6052\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(token_test,y_test, verbose=False)\n",
    "print(\"\\nTesting Accuracy:  {:.4f}\".format(accuracy))\n",
    "print(\"Testing loss:  {:.4f}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
