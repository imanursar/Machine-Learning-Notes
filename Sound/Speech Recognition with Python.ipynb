{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Speech Recognition with Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech Recognition from Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as speech_recog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert speech to text the one and only class we need is the Recognizer\n",
    "class from speech_recognition module. Depending upon the underlying API used to convert speech to text, the Recognizer class has following methods: \n",
    "\n",
    "recognize_sphinx()\n",
    "recognize_bing(): Uses Microsoft Bing Speech API\n",
    "recognize_google(): Uses Google Speech API\n",
    "recognize_google_cloud(): Uses Google Cloud Speech API\n",
    "recognize_houndify(): Uses Houndify API by Sound Hound\n",
    "recognize_ibm(): Uses IBM Speech to Text API\n",
    "recognize_sphinx(): Uses PocketSphinx API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_audio = speech_recog.AudioFile('OSR_us_000_0018_8k.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the recognize_google() method requires the AudioData object of the speech_recognition module as a parameter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert our audio file to an AudioData object, we can use the record() method of the Recognizer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "recog = speech_recog.Recognizer()\n",
    "with sample_audio as audio_file:\n",
    "    audio_content = recog.record(audio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can simply pass the audio_content object to the recognize_google() method of the Recognizer() class object and the audio file will be converted to text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"what's the low to the left shoulder take the winding path reach the lake no closely the size of the gas tank wife degrees off is dirty face men to call before you go out the Redwood Valley strain and hung limp the stray cat gave birth to kittens the young girl gave no clear response the meal was cooked before the bell rang what Joy there is a living\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recog.recognize_google(audio_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Duration and Offset Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of transcribing the complete speech, you can also transcribe a particular segment of the audio file. For instance, if you want to transcribe only the first 10 seconds of the audio file, you need to pass 10 as the value for the duration parameter of the record() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"what's the low to the left shoulder take the winding path reach the lake no closely the size of the gas\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with sample_audio as audio_file:\n",
    "    audio_content = recog.record(audio_file, duration=10)\n",
    "    \n",
    "recog.recognize_google(audio_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can skip some part of the audio file from the beginning using the offset parameter. For instance, if you do not want to transcribe the first 4 seconds of the audio, pass 4 as the value for the offset attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"it's a winding path reach the lake no closely the size of the gas tank wipe degrees off is dirty face\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with sample_audio as audio_file:\n",
    "    audio_content = recog.record(audio_file, offset=4, duration=10)\n",
    "    \n",
    "recog.recognize_google(audio_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An audio file can contain noise due to several reasons. Noise can actually affect the quality of speech to text translation. To reduce noise, the Recognizer class contains adjust_for_ambient_noise() method, which takes the\n",
    "AudioData object as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"what's the low to the left shoulder take the winding path leads to make no closely the size of the gas tank white degrees off is dirty face before you go out the wristlet Bali strain and hung limp the stray cat gave birth to kittens the young girl gave no clear response the meal was cooked before the bell rang what Joy there is a living\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with sample_audio as audio_file:\n",
    "    recog.adjust_for_ambient_noise(audio_file)\n",
    "    audio_content = recog.record(audio_file)\n",
    "    \n",
    "recog.recognize_google(audio_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech Recognition from Live Microphone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To capture the audio from a microphone, we need to first create an object of the Microphone class of the Speach_Recogniton module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic = speech_recog.Microphone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' - Input',\n",
       " 'Microphone (Realtek(R) Audio)',\n",
       " 'Stereo Mix (Realtek(R) Audio)',\n",
       " ' - Output',\n",
       " 'Speakers (Realtek(R) Audio)',\n",
       " 'Primary Sound Capture Driver',\n",
       " 'Microphone (Realtek(R) Audio)',\n",
       " 'Stereo Mix (Realtek(R) Audio)',\n",
       " 'Primary Sound Driver',\n",
       " 'Speakers (Realtek(R) Audio)',\n",
       " 'Speakers (Realtek(R) Audio)',\n",
       " 'Stereo Mix (Realtek(R) Audio)',\n",
       " 'Microphone (Realtek(R) Audio)',\n",
       " 'Speakers (Realtek HD Audio output)',\n",
       " 'Stereo Mix (Realtek HD Audio Stereo input)',\n",
       " 'SPDIF Out (Realtek HDA SPDIF Out)',\n",
       " 'Microphone (Realtek HD Audio Mic input)',\n",
       " 'Speakers (Nahimic mirroring Wave Speaker)']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech_recog.Microphone.list_microphone_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to capture the audio from the microphone. To do so, you need to call the listen() method of the Recognizer() class. Like the record() method, the listen() method also returns the speech_recognition.AudioData object, which can then be passed to the recognize_google() method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak Please\n",
      "Converting Speech to Text...\n",
      "You said: conclusion useful application in the domain of human-computer interaction and automatic speech transcription explain the process of the brain and explains how to translate speech to text\n"
     ]
    }
   ],
   "source": [
    "with mic as audio_file:\n",
    "    print(\"Speak Please\")\n",
    "    recog.adjust_for_ambient_noise(audio_file)\n",
    "    audio = recog.listen(audio_file)\n",
    "    print(\"Converting Speech to Text...\")\n",
    "try:\n",
    "        print(\"You said: \" + recog.recognize_google(audio))\n",
    "except Exception as e:\n",
    "        print(\"Error: \" + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
